{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data=load_diabetes()\n",
    "# Printing the complete dataset\n",
    "print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing dffrent infoemations about the datasets\n",
    "print(data.keys(),end='\\n\\n')           # Keys of the dataset\n",
    "print(data.DESCR,end='\\n\\n')            #A small discription about the dataset\n",
    "print('type is : ', type(data))         # Checking the type of dataset\n",
    "print(\"All the columns are \",data.feature_names)\n",
    "print('data File name : ', data.data_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.target)                      #Printing the target values of the dataset\n",
    "print(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dictonary data to a tabular data so we can operate fast and visualize better\n",
    "diaTable = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# print(diaTable)\n",
    "# printing the first n=7 data from the dataset  default=5\n",
    "diaTable.head(7)\n",
    "\n",
    "# Adding a new Col Ans and storing the target values\n",
    "diaTable['Ans']=data.target\n",
    "print(diaTable.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking is there any NULL values is in the dataset or not\n",
    "print(diaTable.isnull().head(3))            # Printing it with a head value\n",
    "print()\n",
    "print(diaTable.isnull().sum())              # Printing the sum of all the missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till Now We Have only worked with the data \n",
    "- Extracting it\n",
    "- Printing the required Informations\n",
    "- Converting it to the Tabular format to work \n",
    "- Checking the Missing values\n",
    "\n",
    "**Now we are Gonna work and train with the models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=diaTable.drop('Ans',axis=1)                   # Table without ans column\n",
    "Y=diaTable['Ans']                               # Only ans column of the Tabel for training purpose\n",
    "\n",
    "trainTable, testTable, trainAns, testAns = train_test_split(X,Y,test_size=.2, random_state=random.randint(1,15))\n",
    "# The Above statement will split the data X,Y into 2 section train and test \n",
    "# X will create the Table section as it is in table \n",
    "# Y will Create the answer section\n",
    "# test_size is the amount of data will be put for testing purpose -> .2 = 20 % random data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trainTable shape : ', trainTable.shape)\n",
    "print(trainTable.head())\n",
    "print('trainAns shape : ', trainAns.shape)\n",
    "print(trainAns.head())\n",
    "print('testTable shape : ', testTable.shape)\n",
    "print(testTable.head())\n",
    "print('testAns shape : ', testAns.shape)\n",
    "print(testAns.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splited the data into train and test sections**\n",
    "\n",
    "using the train_test_split function avilable in the module<br>\n",
    "Then followed by printing the All the tables (head of 5 values) and their shape just for the sake of confirmation\n",
    "\n",
    "*Now we have the Required data collection. We are starting Machine Learning Process Now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Importing the Linear Regression Model \n",
    "# Importing the Mean Squared error functions to claculate the errors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FITTING THE LINEAR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model -> name of the model which we created \n",
    "model = LinearRegression()              # Model has been Created Now feeding the data is remaining \n",
    "model.fit(trainTable,trainAns)          # Here we are feeding the data with train tables and their answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to predict the values of Test data using the model which we created\n",
    "trainpre = model.predict(trainTable)\n",
    "\n",
    "# The Answers are predictied in the form of N-D Array and stored in trainpre``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the errors in the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now checking the error produced in by the model in the training data only\n",
    "# In the previous section we trained the data in training data only\n",
    "rmse= np.sqrt(mean_squared_error(trainAns,trainpre))\n",
    "\n",
    "# Taking the sqrt of MSE of (Real Ans , Predictied Ans)\n",
    "\n",
    "print('Model Performance in the training data is ')\n",
    "print('RMSE = {}'.format(rmse))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now working in the Testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the from the test data\n",
    "Prediction = model.predict(testTable)\n",
    "rmse= np.sqrt(mean_squared_error(Prediction, testAns))\n",
    "\n",
    "print('Model performance in testing set ')\n",
    "print('RMSR = {}'.format(rmse))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the datapoints in graph\n",
    "\n",
    "\n",
    "I don't have any explanation of this code.<br>\n",
    "Still to learn the Matplotlib Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as ppt\n",
    "# Imported the pyplot module which is from matplotlib\n",
    "\n",
    "ppt.figure(figsize=(10,10))                 # Makes the canvas to plot\n",
    "ppt.scatter(testAns, Prediction)            # Plots the points \n",
    "\n",
    "ppt.xlabel('Actual')\n",
    "ppt.ylabel('Prediction')\n",
    "\n",
    "# Drawn something Random Need to work on this \n",
    "ppt.plot([min(Prediction),max(Prediction)],[min(Prediction),max(Prediction)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
